{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f453c01",
   "metadata": {},
   "source": [
    "# Importing Required Libraries and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import shap\n",
    "from itertools import combinations\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc94965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/max1024/Downloads/drw-crypto-market-prediction/\"\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944dfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(data_path + \"train.parquet\")\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8699e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet(data_path + \"test.parquet\")\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf320e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a09bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.read_csv(\"../data/feature_importance_20250723_2205.csv\")\n",
    "print(feature_importance_df.shape)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_list = feature_importance_df[\"Feature\"].tolist()\n",
    "print(len(selected_features_list))\n",
    "selected_features_list[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69197461",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols_list = []\n",
    "for f in selected_features_list:\n",
    "    f_list = f.split(\"_\")\n",
    "    for col in f_list:\n",
    "        if \"X\" in col:\n",
    "            selected_cols_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228757cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols_list = list(set(selected_cols_list))\n",
    "len(selected_cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in train_df.columns if col not in selected_cols_list]\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d424478",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.remove(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d026da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=cols_to_drop)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd907b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=cols_to_drop)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = train_df.drop(columns=[\"label\"]).columns.tolist()\n",
    "print(len(feature_list))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_feat_engi(df):\n",
    "    df = df.copy()\n",
    "    new_features = {}\n",
    "\n",
    "    new_features['row_mean'] = df[feature_list].mean(axis=1)\n",
    "    new_features['row_std'] = df[feature_list].std(axis=1)\n",
    "    new_features['row_max'] = df[feature_list].max(axis=1)\n",
    "    new_features['row_min'] = df[feature_list].min(axis=1)\n",
    "    new_features['row_sum'] = df[feature_list].sum(axis=1)\n",
    "\n",
    "    for i in tqdm(range(19)):\n",
    "        nth = round(0.05 + i * 0.05, 2)\n",
    "        new_features['row_{}_quantile'.format(nth)] = df[feature_list].quantile(q=nth, axis=1)\n",
    "\n",
    "    new_feats_df = pd.DataFrame(new_features, index=df.index)\n",
    "    result_df = pd.concat([df, new_feats_df], axis=1)\n",
    "\n",
    "    return result_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0136f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = row_wise_feat_engi(train_df)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01963bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = row_wise_feat_engi(test_df)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef5a9e",
   "metadata": {},
   "source": [
    "### Nonlinear transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_features_list = ['X758',\n",
    " 'X757',\n",
    " 'X272',\n",
    " 'X614',\n",
    " 'X752',\n",
    " 'X772',\n",
    " 'X753',\n",
    " 'X759',\n",
    " 'X756',\n",
    " 'X27',\n",
    " 'X605',\n",
    " 'X25',\n",
    " 'X774',\n",
    " 'X332',\n",
    " 'X607',\n",
    " 'X648',\n",
    " 'X754',\n",
    " 'X329',\n",
    " 'X767',\n",
    " 'X280']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_feat_engi(df):\n",
    "    df = df.copy()\n",
    "    new_features = {}\n",
    "\n",
    "    for f in tqdm(top_20_features_list):\n",
    "        new_features[\"{}_percentile_rank\".format(f)] = df[f].rank(pct=True)\n",
    "        new_features[\"{}_square\".format(f)] = df[f].apply(lambda x: x**2)\n",
    "        new_features[\"{}_cube\".format(f)] = df[f].apply(lambda x: x**3)\n",
    "        new_features[\"{}_sqrt\".format(f)] = df[f].apply(lambda x: np.sqrt(np.abs(x)))\n",
    "        new_features[\"{}_log1p\".format(f)] = df[f].apply(lambda x: np.log1p(np.abs(x)))\n",
    "        new_features[\"{}_exp\".format(f)] = df[f].apply(lambda x: np.exp(x))\n",
    "        new_features[\"{}_sin\".format(f)] = df[f].apply(lambda x: np.sin(x))\n",
    "        new_features[\"{}_cos\".format(f)] = df[f].apply(lambda x: np.cos(x))\n",
    "        new_features[\"{}_tanh\".format(f)] = df[f].apply(lambda x: np.tanh(x))\n",
    "        new_features[\"{}_abs\".format(f)] = df[f].apply(lambda x: np.abs(x))\n",
    "    \n",
    "    new_feats_df = pd.DataFrame(new_features, index=df.index)\n",
    "    result_df = pd.concat([df, new_feats_df], axis=1)\n",
    "\n",
    "    return result_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = nonlinear_feat_engi(train_df)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = nonlinear_feat_engi(test_df)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4b0dd",
   "metadata": {},
   "source": [
    "### Interaction feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_feat_engi(df):\n",
    "    df = df.copy()\n",
    "    new_features = {}\n",
    "\n",
    "    for f1, f2 in combinations(top_20_features_list, 2):\n",
    "        new_features[f'{f1}_{f2}_prod'] = df[f1] * df[f2]\n",
    "        new_features[f'{f1}_{f2}_sum'] = df[f1] + df[f2]\n",
    "        new_features[f'{f1}_{f2}_diff'] = df[f1] - df[f2]\n",
    "        new_features[f'{f1}_{f2}_ratio'] = df[f1] / (df[f2] + 1e-5)\n",
    "        new_features[f'{f1}_{f2}_max'] = df[[f1, f2]].max(axis=1)\n",
    "        new_features[f'{f1}_{f2}_min'] = df[[f1, f2]].min(axis=1)\n",
    "        new_features[f'{f1}_{f2}_absdiff'] = np.abs(df[f1] - df[f2])\n",
    "\n",
    "    new_feats_df = pd.DataFrame(new_features, index=df.index)\n",
    "    result_df = pd.concat([df, new_feats_df], axis=1)\n",
    "\n",
    "    return result_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4566492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = interaction_feat_engi(train_df)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c01ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = interaction_feat_engi(test_df)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in train_df.columns if col not in selected_features_list]\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[selected_features_list + [\"label\"]]\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[selected_features_list + [\"label\"]]\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49dee42",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a464b2",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optunahub\n",
    "from optuna.visualization import plot_slice, plot_param_importances\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadede40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current time in the local timezone\n",
    "current_time_local = datetime.datetime.now()\n",
    "print(f\"Current time (local): {current_time_local}\"[:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_param_tune(optuna_n_trials):\n",
    "\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    base_params = {\n",
    "        \"num_iterations\": 50000,\n",
    "        \"early_stopping_round\": 1000,\n",
    "        \"device\": \"gpu\",\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "        num_features = trial.suggest_int('num_features', 30, len(selected_features_list))\n",
    "\n",
    "        X = train_df.drop(columns=[\"label\"]).iloc[:, :num_features]\n",
    "        y = train_df[\"label\"]\n",
    "\n",
    "\n",
    "        params_to_tune = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 3e-4, 9e-2),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 150),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "            'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 0.4),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 0, 15),\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 0, 200),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1),\n",
    "        }\n",
    "\n",
    "        oof_preds = np.full(len(train_df), np.nan)\n",
    "\n",
    "        for i, (train_idx, val_idx) in enumerate(tscv.split(train_df)):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = LGBMRegressor(**base_params, **params_to_tune)\n",
    "\n",
    "            model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "\n",
    "            val_preds = model.predict(X_val)\n",
    "\n",
    "            oof_preds[val_idx] = val_preds\n",
    "\n",
    "        mask = ~np.isnan(oof_preds)\n",
    "        score = np.corrcoef(y[mask], oof_preds[mask])[0, 1]\n",
    "            \n",
    "        return score\n",
    "\n",
    "    with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "    \n",
    "        # Define a callback function to update the progress bar\n",
    "        def progress_bar_callback(study, trial):\n",
    "            pbar.update(1)\n",
    "    \n",
    "        current_time_local = datetime.datetime.now()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optunahub.load_module(\"samplers/auto_sampler\").AutoSampler(),\n",
    "            storage=\"sqlite:////home/max1024/Kaggle/drw2/optuna_study/db.sqlite3\",\n",
    "            study_name=f\"DRW_LGB_param_tune_{current_time_local}\"[:-7]\n",
    "        )\n",
    "        study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study = lgb_param_tune(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3095f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbe013",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccef774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_param_tune(optuna_n_trials):\n",
    "    \n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    base_params = {\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'n_estimators': 50000,\n",
    "        'verbosity': 0,\n",
    "        'early_stopping_rounds': 1000\n",
    "    }\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "        num_features = trial.suggest_int('num_features', 30, len(selected_features_list))\n",
    "\n",
    "        X = train_df.drop(columns=[\"label\"]).iloc[:, :num_features]\n",
    "        y = train_df[\"label\"]\n",
    "\n",
    "        params_to_tune = {            \n",
    "            'learning_rate': trial.suggest_float('learning_rate', 3e-4, 9e-2),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 200),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 800),\n",
    "            'min_child_weight': trial.suggest_float('min_child_weight', 0, 200),\n",
    "            'min_split_loss': trial.suggest_float('min_split_loss', 0, 200),\n",
    "        }\n",
    "\n",
    "        oof_preds = np.full(len(train_df), np.nan)\n",
    "\n",
    "        for i, (train_idx, val_idx) in enumerate(tscv.split(train_df)):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = XGBRegressor(**base_params, **params_to_tune)\n",
    "\n",
    "            model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], verbose=0)\n",
    "\n",
    "            val_preds = model.predict(X_val)\n",
    "\n",
    "            oof_preds[val_idx] = val_preds\n",
    "\n",
    "        mask = ~np.isnan(oof_preds)\n",
    "        score = np.corrcoef(y[mask], oof_preds[mask])[0, 1]\n",
    "            \n",
    "        return score\n",
    "\n",
    "    with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "    \n",
    "        # Define a callback function to update the progress bar\n",
    "        def progress_bar_callback(study, trial):\n",
    "            pbar.update(1)\n",
    "    \n",
    "        current_time_local = datetime.datetime.now()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optunahub.load_module(\"samplers/auto_sampler\").AutoSampler(),\n",
    "            storage=\"sqlite:////home/max1024/Kaggle/drw2/optuna_study/db.sqlite3\",\n",
    "            study_name=f\"DRW_XGB_param_tune_{current_time_local}\"[:-7]\n",
    "        )\n",
    "        study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_study = xgb_param_tune(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8eb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a04fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_param_tune(optuna_n_trials):\n",
    "    \n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    base_params = {\n",
    "        'iterations': 50000,\n",
    "        'verbose': 0,\n",
    "        'task_type': 'GPU',\n",
    "        'use_best_model': True,\n",
    "        'early_stopping_rounds': 1000\n",
    "    }\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "        num_features = trial.suggest_int('num_features', 30, len(selected_features_list))\n",
    "\n",
    "        X = train_df.drop(columns=[\"label\"]).iloc[:, :num_features]\n",
    "        y = train_df[\"label\"]\n",
    "\n",
    "        params_to_tune = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 3e-4, 9e-2),\n",
    "            'depth': trial.suggest_int('depth', 4, 8),\n",
    "            'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 800),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 3),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 40)\n",
    "        }\n",
    "\n",
    "        oof_preds = np.full(len(train_df), np.nan)\n",
    "\n",
    "        for i, (train_idx, val_idx) in enumerate(tscv.split(train_df)):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = CatBoostRegressor(**base_params, **params_to_tune)\n",
    "\n",
    "            model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "            val_preds = model.predict(X_val)\n",
    "\n",
    "            oof_preds[val_idx] = val_preds\n",
    "\n",
    "        mask = ~np.isnan(oof_preds)\n",
    "        score = np.corrcoef(y[mask], oof_preds[mask])[0, 1]\n",
    "            \n",
    "        return score\n",
    "\n",
    "    with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "    \n",
    "        # Define a callback function to update the progress bar\n",
    "        def progress_bar_callback(study, trial):\n",
    "            pbar.update(1)\n",
    "    \n",
    "        current_time_local = datetime.datetime.now()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optunahub.load_module(\"samplers/auto_sampler\").AutoSampler(),\n",
    "            storage=\"sqlite:////home/max1024/Kaggle/drw2/optuna_study/db.sqlite3\",\n",
    "            study_name=f\"DRW_Catboost_param_tune_{current_time_local}\"[:-7]\n",
    "        )\n",
    "        study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ba6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_study = catboost_param_tune(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29572b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
